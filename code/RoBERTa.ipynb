{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RoBERTa.ipynb","provenance":[],"collapsed_sections":["zjPSDG7MLfYu"],"authorship_tag":"ABX9TyPsSHfErjbRC0yqYkpLTaB3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"zjPSDG7MLfYu"},"source":["# Read Data"]},{"cell_type":"code","metadata":{"id":"gsdJLlUUI3AE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605879078687,"user_tz":-480,"elapsed":37509,"user":{"displayName":"Lin CHENG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ktQ7itlqm_xlrJQa92rKtAgFOnq06TeqdgYR=s64","userId":"15737879624843884018"}},"outputId":"b10b786b-1fc1-4d8c-8cce-8524cf4d9600"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J16MlSXQJ09P"},"source":["# !pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"piNviRuLJfY7"},"source":["import numpy as np\n","import pandas as pd\n","from math import ceil, floor\n","import tensorflow as tf\n","import tensorflow_probability as tfp\n","import tensorflow.keras.layers as L\n","from tensorflow.keras.initializers import TruncatedNormal\n","from sklearn.model_selection import train_test_split\n","from transformers import BertConfig, TFBertPreTrainedModel, TFBertMainLayer\n","from transformers import RobertaConfig, TFRobertaPreTrainedModel, TFRobertaMainLayer, TFRobertaModel\n","from tokenizers import BertWordPieceTokenizer, ByteLevelBPETokenizer\n","import matplotlib.pyplot as plt\n","from tqdm.autonotebook import tqdm\n","from joblib import Parallel, delayed\n","import os\n","\n","import logging\n","tf.get_logger().setLevel(logging.ERROR)\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GyIMybyFJf7S"},"source":["#read data\n","train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/6000/tweet-sentiment-extraction/train.csv', header = 0).dropna()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DcGujk_kJf93","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1605517566009,"user_tz":-480,"elapsed":839,"user":{"displayName":"Lin CHENG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ktQ7itlqm_xlrJQa92rKtAgFOnq06TeqdgYR=s64","userId":"15737879624843884018"}},"outputId":"b9a8f8ac-636d-4f99-e860-f2a2e28dbf7e"},"source":["train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>selected_text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cb774db0d1</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>549e992a42</td>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>Sooo SAD</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>088c60f138</td>\n","      <td>my boss is bullying me...</td>\n","      <td>bullying me</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9642c003ef</td>\n","      <td>what interview! leave me alone</td>\n","      <td>leave me alone</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>358bd9e861</td>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>Sons of ****,</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>27476</th>\n","      <td>4eac33d1c0</td>\n","      <td>wish we could come see u on Denver  husband l...</td>\n","      <td>d lost</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>27477</th>\n","      <td>4f4c4fc327</td>\n","      <td>I`ve wondered about rake to.  The client has ...</td>\n","      <td>, don`t force</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>27478</th>\n","      <td>f67aae2310</td>\n","      <td>Yay good for both of you. Enjoy the break - y...</td>\n","      <td>Yay good for both of you.</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>27479</th>\n","      <td>ed167662a5</td>\n","      <td>But it was worth it  ****.</td>\n","      <td>But it was worth it  ****.</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>27480</th>\n","      <td>6f7127d9d7</td>\n","      <td>All this flirting going on - The ATG smiles...</td>\n","      <td>All this flirting going on - The ATG smiles. Y...</td>\n","      <td>neutral</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>27480 rows Ã— 4 columns</p>\n","</div>"],"text/plain":["           textID  ... sentiment\n","0      cb774db0d1  ...   neutral\n","1      549e992a42  ...  negative\n","2      088c60f138  ...  negative\n","3      9642c003ef  ...  negative\n","4      358bd9e861  ...  negative\n","...           ...  ...       ...\n","27476  4eac33d1c0  ...  negative\n","27477  4f4c4fc327  ...  negative\n","27478  f67aae2310  ...  positive\n","27479  ed167662a5  ...  positive\n","27480  6f7127d9d7  ...   neutral\n","\n","[27480 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"8d0sz0MZLCQe"},"source":["def jaccard(str1, str2): \n","    a = set(str(str1).lower().split()) \n","    b = set(str(str2).lower().split())\n","    c = a.intersection(b)\n","    return float(len(c)) / (len(a) + len(b) - len(c))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AO98Ga64LjUa"},"source":["# Data Preprocessing"]},{"cell_type":"code","metadata":{"id":"34IsjYpgRHv2"},"source":["Y = train['selected_text']\n","X = train.drop(columns=['selected_text'])\n","X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SfUGRhojRUxh"},"source":["Y_train = pd.DataFrame(Y_train)\n","train = X_train.join(Y_train)\n","test = X_test.copy()\n","Y_test = pd.DataFrame(Y_test)\n","sample = X_test.join(Y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ghxtXz2kSKN0"},"source":["index1 = pd.DataFrame([i for i in range(train.shape[0])])\n","train.set_index(index1[0],inplace= True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h-o1TEOmSKq7"},"source":["index2 = pd.DataFrame([i for i in range(test.shape[0])])\n","test.set_index(index2[0],inplace= True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ulwdPj6gZ0Ml"},"source":["index3 = pd.DataFrame([i for i in range(sample.shape[0])])\n","sample.set_index(index3[0],inplace= True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7TWiQmWJTRYu","colab":{"base_uri":"https://localhost:8080/","height":450},"executionInfo":{"status":"ok","timestamp":1605517569460,"user_tz":-480,"elapsed":581,"user":{"displayName":"Lin CHENG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ktQ7itlqm_xlrJQa92rKtAgFOnq06TeqdgYR=s64","userId":"15737879624843884018"}},"outputId":"e2e9772b-7214-4c56-f78a-fc890cbab689"},"source":["train"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","      <th>selected_text</th>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1376de5329</td>\n","      <td>Just Finished My English Final...Just One Step...</td>\n","      <td>neutral</td>\n","      <td>Just Finished My English Final...Just One Step...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>aac1cc6fd4</td>\n","      <td>Also with the not driving part i could afford ...</td>\n","      <td>positive</td>\n","      <td>save ev</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9672b4ee61</td>\n","      <td>GREEN DAY IS PERFORMING ON SNL NEXT WEEK!  sor...</td>\n","      <td>neutral</td>\n","      <td>sorry, that made me happy and i`m still all di...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>44e7f97625</td>\n","      <td>I am never going to get these pictures taken</td>\n","      <td>neutral</td>\n","      <td>I am never going to get these pictures taken</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ab1368e993</td>\n","      <td>why thank you. Couldn`t resist it</td>\n","      <td>neutral</td>\n","      <td>why thank you. Couldn`t resist it</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>21979</th>\n","      <td>fcc45b5d05</td>\n","      <td>_girl - Bummer...mail came but package didn`t</td>\n","      <td>negative</td>\n","      <td>Bummer..</td>\n","    </tr>\n","    <tr>\n","      <th>21980</th>\n","      <td>62ae10ec84</td>\n","      <td>My trip to Igbaras will be postponed to next week</td>\n","      <td>neutral</td>\n","      <td>My trip to Igbaras will be postponed to next week</td>\n","    </tr>\n","    <tr>\n","      <th>21981</th>\n","      <td>66ab9d1f77</td>\n","      <td>Just an observation: Aside from the riverwalk,...</td>\n","      <td>neutral</td>\n","      <td>Just an observation: Aside from the riverwalk,...</td>\n","    </tr>\n","    <tr>\n","      <th>21982</th>\n","      <td>35d06c1169</td>\n","      <td>Probably because it wasnt a command...bet you ...</td>\n","      <td>neutral</td>\n","      <td>Probably because it wasnt a command...bet you ...</td>\n","    </tr>\n","    <tr>\n","      <th>21983</th>\n","      <td>4bda359cbb</td>\n","      <td>Done at the spa   now meeting vic for some lat...</td>\n","      <td>neutral</td>\n","      <td>Done at the spa   now meeting vic for some lat...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>21984 rows Ã— 4 columns</p>\n","</div>"],"text/plain":["           textID  ...                                      selected_text\n","0                  ...                                                   \n","0      1376de5329  ...  Just Finished My English Final...Just One Step...\n","1      aac1cc6fd4  ...                                            save ev\n","2      9672b4ee61  ...  sorry, that made me happy and i`m still all di...\n","3      44e7f97625  ...       I am never going to get these pictures taken\n","4      ab1368e993  ...                  why thank you. Couldn`t resist it\n","...           ...  ...                                                ...\n","21979  fcc45b5d05  ...                                           Bummer..\n","21980  62ae10ec84  ...  My trip to Igbaras will be postponed to next week\n","21981  66ab9d1f77  ...  Just an observation: Aside from the riverwalk,...\n","21982  35d06c1169  ...  Probably because it wasnt a command...bet you ...\n","21983  4bda359cbb  ...  Done at the spa   now meeting vic for some lat...\n","\n","[21984 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"CPbsDo7XTSw9","colab":{"base_uri":"https://localhost:8080/","height":450},"executionInfo":{"status":"ok","timestamp":1605517570186,"user_tz":-480,"elapsed":793,"user":{"displayName":"Lin CHENG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ktQ7itlqm_xlrJQa92rKtAgFOnq06TeqdgYR=s64","userId":"15737879624843884018"}},"outputId":"95688a39-e3bb-4aca-b4d7-a56f7ba0a978"},"source":["test"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>50726f1adb</td>\n","      <td>smH daTs whacK</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8a87bf47ff</td>\n","      <td>oh dear, thats not good - I hope you get thro...</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>f90dccdae7</td>\n","      <td>this hole twitter thing is new too me, its not...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>884476afed</td>\n","      <td>@_elj Appreciated,uni email is helpful..</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1f27adbaa5</td>\n","      <td>, Just read an article that buying IP`s doesn...</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5491</th>\n","      <td>b5e3b51d4c</td>\n","      <td>MC, happy mother`s day to your mom ;).. love yah</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>5492</th>\n","      <td>7bb003fcac</td>\n","      <td>Glad you are happy!</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>5493</th>\n","      <td>5f4484b1e4</td>\n","      <td>mcfly anit been on here in ages  z</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>5494</th>\n","      <td>8e74e2abc3</td>\n","      <td>that`s not good to hear!  i hope everything i...</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>5495</th>\n","      <td>700eb9d742</td>\n","      <td>Went out to get groceries...prices are inflati...</td>\n","      <td>negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5496 rows Ã— 3 columns</p>\n","</div>"],"text/plain":["          textID                                               text sentiment\n","0                                                                            \n","0     50726f1adb                                     smH daTs whacK   neutral\n","1     8a87bf47ff   oh dear, thats not good - I hope you get thro...   neutral\n","2     f90dccdae7  this hole twitter thing is new too me, its not...  negative\n","3     884476afed           @_elj Appreciated,uni email is helpful..  positive\n","4     1f27adbaa5   , Just read an article that buying IP`s doesn...   neutral\n","...          ...                                                ...       ...\n","5491  b5e3b51d4c   MC, happy mother`s day to your mom ;).. love yah  positive\n","5492  7bb003fcac                                Glad you are happy!  positive\n","5493  5f4484b1e4                 mcfly anit been on here in ages  z   neutral\n","5494  8e74e2abc3   that`s not good to hear!  i hope everything i...   neutral\n","5495  700eb9d742  Went out to get groceries...prices are inflati...  negative\n","\n","[5496 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"markdown","metadata":{"id":"SkoffgvupgZW"},"source":["#training"]},{"cell_type":"code","metadata":{"id":"4tRSmtc2LC58"},"source":["MAX_SEQUENCE_LEN = 96\n","tokenizer = tokenizers.ByteLevelBPETokenizer(\n","    vocab='/content/drive/My Drive/Colab Notebooks/6000/vocab-roberta-base.json', \n","    merges='/content/drive/My Drive/Colab Notebooks/6000/merges-roberta-base.txt', \n","    lowercase=True,\n","    add_prefix_space=True\n",")\n","sentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hvRptLFFLC9C"},"source":["ct = train.shape[0]\n","input_ids = np.ones((ct,MAX_SEQUENCE_LEN),dtype='int32')\n","attention_mask = np.zeros((ct,MAX_SEQUENCE_LEN),dtype='int32')\n","token_type_ids = np.zeros((ct,MAX_SEQUENCE_LEN),dtype='int32')\n","start_tokens = np.zeros((ct,MAX_SEQUENCE_LEN),dtype='int32')\n","end_tokens = np.zeros((ct,MAX_SEQUENCE_LEN),dtype='int32')\n","\n","for k in range(train.shape[0]):\n","    \n","    # FIND OVERLAP\n","    text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n","    text2 = \" \".join(train.loc[k,'selected_text'].split())\n","    idx = text1.find(text2)\n","    chars = np.zeros((len(text1)))\n","    chars[idx:idx+len(text2)]=1\n","    if text1[idx-1]==' ': chars[idx-1] = 1 \n","    enc = tokenizer.encode(text1) \n","        \n","    # ID_OFFSETS\n","    offsets = []; idx=0\n","    for t in enc.ids:\n","        w = tokenizer.decode([t])\n","        offsets.append((idx,idx+len(w)))\n","        idx += len(w)\n","    \n","    # START END TOKENS\n","    toks = []\n","    for i,(a,b) in enumerate(offsets):\n","        sm = np.sum(chars[a:b])\n","        if sm>0: toks.append(i) \n","        \n","    s_tok = sentiment_id[train.loc[k,'sentiment']]\n","    input_ids[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n","    attention_mask[k,:len(enc.ids)+5] = 1\n","    if len(toks)>0:\n","        start_tokens[k,toks[0]+1] = 1\n","        end_tokens[k,toks[-1]+1] = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L3a17yVvLDA-"},"source":["ct = test.shape[0]\n","input_ids_t = np.ones((ct,MAX_SEQUENCE_LEN),dtype='int32')\n","attention_mask_t = np.zeros((ct,MAX_SEQUENCE_LEN),dtype='int32')\n","token_type_ids_t = np.zeros((ct,MAX_SEQUENCE_LEN),dtype='int32')\n","\n","for k in range(test.shape[0]):\n","        \n","    # INPUT_IDS\n","    text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n","    enc = tokenizer.encode(text1)                \n","    s_tok = sentiment_id[test.loc[k,'sentiment']]\n","    input_ids_t[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n","    attention_mask_t[k,:len(enc.ids)+5] = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QKrdS348LDKH"},"source":["def build_model():\n","    ids = tf.keras.layers.Input((MAX_SEQUENCE_LEN,), dtype=tf.int32)\n","    att = tf.keras.layers.Input((MAX_SEQUENCE_LEN,), dtype=tf.int32)\n","    tok = tf.keras.layers.Input((MAX_SEQUENCE_LEN,), dtype=tf.int32)\n","\n","    config = RobertaConfig.from_pretrained('/content/drive/My Drive/Colab Notebooks/6000/config-roberta-base.json')\n","    bert_model = TFRobertaModel.from_pretrained('/content/drive/My Drive/Colab Notebooks/6000/pretrained-roberta-base.h5',config=config)\n","    x = bert_model(ids,attention_mask=att,token_type_ids=tok)\n","    \n","    x1 = tf.keras.layers.Dropout(0.1)(x[0]) \n","    x1 = tf.keras.layers.Conv1D(1,1)(x1)\n","    x1 = tf.keras.layers.Flatten()(x1)\n","    x1 = tf.keras.layers.Activation('softmax')(x1)\n","    \n","    x2 = tf.keras.layers.Dropout(0.1)(x[0]) \n","    x2 = tf.keras.layers.Conv1D(1,1)(x2)\n","    x2 = tf.keras.layers.Flatten()(x2)\n","    x2 = tf.keras.layers.Activation('softmax')(x2)\n","\n","    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OZGytkRbpkT5"},"source":["#Prediction&Evaluation"]},{"cell_type":"code","metadata":{"id":"JPeuxJNKLDIP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605521993727,"user_tz":-480,"elapsed":3714368,"user":{"displayName":"Lin CHENG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ktQ7itlqm_xlrJQa92rKtAgFOnq06TeqdgYR=s64","userId":"15737879624843884018"}},"outputId":"6807e58a-f77e-441c-9ca6-d44bec67f4fd"},"source":["jac = []; VER='v0'; DISPLAY=1 # USE display=1 FOR INTERACTIVE\n","oof_start = np.zeros((input_ids.shape[0],MAX_SEQUENCE_LEN))\n","oof_end = np.zeros((input_ids.shape[0],MAX_SEQUENCE_LEN))\n","preds_start = np.zeros((input_ids_t.shape[0],MAX_SEQUENCE_LEN))\n","preds_end = np.zeros((input_ids_t.shape[0],MAX_SEQUENCE_LEN))\n","\n","skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=777)\n","for fold,(idxT,idxV) in enumerate(skf.split(input_ids,train.sentiment.values)):\n","\n","    print('#'*25)\n","    print('### FOLD %i'%(fold+1))\n","    print('#'*25)\n","    \n","    K.clear_session()\n","    model = build_model()\n","        \n","    sv = tf.keras.callbacks.ModelCheckpoint(\n","        '%s-roberta-%i.h5'%(VER,fold), monitor='val_loss', verbose=1, save_best_only=True,\n","        save_weights_only=True, mode='auto', save_freq='epoch')\n","    \n","    model.fit([input_ids[idxT,], attention_mask[idxT,], token_type_ids[idxT,]], [start_tokens[idxT,], end_tokens[idxT,]], \n","        epochs=3, batch_size=32, verbose=DISPLAY, callbacks=[sv],\n","        validation_data=([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]], \n","        [start_tokens[idxV,], end_tokens[idxV,]]))\n","    \n","    print('Loading model...')\n","    model.load_weights('%s-roberta-%i.h5'%(VER,fold))\n","    \n","    print('Predicting OOF...')\n","    oof_start[idxV,],oof_end[idxV,] = model.predict([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]],verbose=DISPLAY)\n","    \n","    print('Predicting Test...')\n","    preds = model.predict([input_ids_t,attention_mask_t,token_type_ids_t],verbose=DISPLAY)\n","    preds_start += preds[0]/skf.n_splits\n","    preds_end += preds[1]/skf.n_splits\n","    \n","    # DISPLAY FOLD JACCARD\n","    all = []\n","    for k in idxV:\n","        a = np.argmax(oof_start[k,])\n","        b = np.argmax(oof_end[k,])\n","        if a>b: \n","            st = train.loc[k,'text'] # IMPROVE CV/LB with better choice here\n","        else:\n","            text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n","            enc = tokenizer.encode(text1)\n","            st = tokenizer.decode(enc.ids[a-1:b])\n","        all.append(jaccard(st,train.loc[k,'selected_text']))\n","    jac.append(np.mean(all))\n","    print('>>>> FOLD %i Jaccard ='%(fold+1),np.mean(all))\n","    print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["#########################\n","### FOLD 1\n","#########################\n"],"name":"stdout"},{"output_type":"stream","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at /content/drive/My Drive/Colab Notebooks/6000/pretrained-roberta-base.h5.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/3\n","550/550 [==============================] - ETA: 0s - loss: 2.2612 - activation_loss: 1.0978 - activation_1_loss: 1.1633\n","Epoch 00001: val_loss improved from inf to 1.65200, saving model to v0-roberta-0.h5\n","550/550 [==============================] - 227s 413ms/step - loss: 2.2612 - activation_loss: 1.0978 - activation_1_loss: 1.1633 - val_loss: 1.6520 - val_activation_loss: 0.8589 - val_activation_1_loss: 0.7931\n","Epoch 2/3\n","550/550 [==============================] - ETA: 0s - loss: 1.6629 - activation_loss: 0.8479 - activation_1_loss: 0.8149\n","Epoch 00002: val_loss improved from 1.65200 to 1.60862, saving model to v0-roberta-0.h5\n","550/550 [==============================] - 226s 411ms/step - loss: 1.6629 - activation_loss: 0.8479 - activation_1_loss: 0.8149 - val_loss: 1.6086 - val_activation_loss: 0.8453 - val_activation_1_loss: 0.7633\n","Epoch 3/3\n","550/550 [==============================] - ETA: 0s - loss: 1.5010 - activation_loss: 0.7710 - activation_1_loss: 0.7300\n","Epoch 00003: val_loss improved from 1.60862 to 1.60829, saving model to v0-roberta-0.h5\n","550/550 [==============================] - 226s 411ms/step - loss: 1.5010 - activation_loss: 0.7710 - activation_1_loss: 0.7300 - val_loss: 1.6083 - val_activation_loss: 0.8406 - val_activation_1_loss: 0.7677\n","Loading model...\n","Predicting OOF...\n","138/138 [==============================] - 18s 132ms/step\n","Predicting Test...\n","172/172 [==============================] - 23s 133ms/step\n",">>>> FOLD 1 Jaccard = 0.7095798610342156\n","\n","#########################\n","### FOLD 2\n","#########################\n"],"name":"stdout"},{"output_type":"stream","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at /content/drive/My Drive/Colab Notebooks/6000/pretrained-roberta-base.h5.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/3\n","550/550 [==============================] - ETA: 0s - loss: 2.2810 - activation_loss: 1.1283 - activation_1_loss: 1.1527\n","Epoch 00001: val_loss improved from inf to 1.67846, saving model to v0-roberta-1.h5\n","550/550 [==============================] - 227s 413ms/step - loss: 2.2810 - activation_loss: 1.1283 - activation_1_loss: 1.1527 - val_loss: 1.6785 - val_activation_loss: 0.8573 - val_activation_1_loss: 0.8211\n","Epoch 2/3\n","550/550 [==============================] - ETA: 0s - loss: 1.8542 - activation_loss: 0.9024 - activation_1_loss: 0.9518\n","Epoch 00002: val_loss did not improve from 1.67846\n","550/550 [==============================] - 224s 407ms/step - loss: 1.8542 - activation_loss: 0.9024 - activation_1_loss: 0.9518 - val_loss: 2.5867 - val_activation_loss: 1.0236 - val_activation_1_loss: 1.5631\n","Epoch 3/3\n","550/550 [==============================] - ETA: 0s - loss: 1.7761 - activation_loss: 0.8755 - activation_1_loss: 0.9006\n","Epoch 00003: val_loss improved from 1.67846 to 1.65654, saving model to v0-roberta-1.h5\n","550/550 [==============================] - 225s 409ms/step - loss: 1.7761 - activation_loss: 0.8755 - activation_1_loss: 0.9006 - val_loss: 1.6565 - val_activation_loss: 0.8470 - val_activation_1_loss: 0.8095\n","Loading model...\n","Predicting OOF...\n","138/138 [==============================] - 18s 133ms/step\n","Predicting Test...\n","172/172 [==============================] - 23s 133ms/step\n",">>>> FOLD 2 Jaccard = 0.70869739256861\n","\n","#########################\n","### FOLD 3\n","#########################\n"],"name":"stdout"},{"output_type":"stream","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at /content/drive/My Drive/Colab Notebooks/6000/pretrained-roberta-base.h5.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/3\n","550/550 [==============================] - ETA: 0s - loss: 2.5284 - activation_loss: 1.2220 - activation_1_loss: 1.3065\n","Epoch 00001: val_loss improved from inf to 1.78828, saving model to v0-roberta-2.h5\n","550/550 [==============================] - 227s 413ms/step - loss: 2.5284 - activation_loss: 1.2220 - activation_1_loss: 1.3065 - val_loss: 1.7883 - val_activation_loss: 0.8783 - val_activation_1_loss: 0.9100\n","Epoch 2/3\n","550/550 [==============================] - ETA: 0s - loss: 1.7288 - activation_loss: 0.8750 - activation_1_loss: 0.8538\n","Epoch 00002: val_loss improved from 1.78828 to 1.65549, saving model to v0-roberta-2.h5\n","550/550 [==============================] - 225s 409ms/step - loss: 1.7288 - activation_loss: 0.8750 - activation_1_loss: 0.8538 - val_loss: 1.6555 - val_activation_loss: 0.8505 - val_activation_1_loss: 0.8050\n","Epoch 3/3\n","550/550 [==============================] - ETA: 0s - loss: 1.5843 - activation_loss: 0.7983 - activation_1_loss: 0.7860\n","Epoch 00003: val_loss did not improve from 1.65549\n","550/550 [==============================] - 223s 406ms/step - loss: 1.5843 - activation_loss: 0.7983 - activation_1_loss: 0.7860 - val_loss: 1.8940 - val_activation_loss: 0.8432 - val_activation_1_loss: 1.0508\n","Loading model...\n","Predicting OOF...\n","138/138 [==============================] - 18s 133ms/step\n","Predicting Test...\n","172/172 [==============================] - 23s 133ms/step\n",">>>> FOLD 3 Jaccard = 0.7106166929044978\n","\n","#########################\n","### FOLD 4\n","#########################\n"],"name":"stdout"},{"output_type":"stream","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at /content/drive/My Drive/Colab Notebooks/6000/pretrained-roberta-base.h5.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/3\n","550/550 [==============================] - ETA: 0s - loss: 2.2276 - activation_loss: 1.1061 - activation_1_loss: 1.1215\n","Epoch 00001: val_loss improved from inf to 1.68816, saving model to v0-roberta-3.h5\n","550/550 [==============================] - 228s 415ms/step - loss: 2.2276 - activation_loss: 1.1061 - activation_1_loss: 1.1215 - val_loss: 1.6882 - val_activation_loss: 0.8554 - val_activation_1_loss: 0.8327\n","Epoch 2/3\n","550/550 [==============================] - ETA: 0s - loss: 1.6790 - activation_loss: 0.8605 - activation_1_loss: 0.8184\n","Epoch 00002: val_loss improved from 1.68816 to 1.66411, saving model to v0-roberta-3.h5\n","550/550 [==============================] - 225s 410ms/step - loss: 1.6790 - activation_loss: 0.8605 - activation_1_loss: 0.8184 - val_loss: 1.6641 - val_activation_loss: 0.8254 - val_activation_1_loss: 0.8387\n","Epoch 3/3\n","550/550 [==============================] - ETA: 0s - loss: 1.5110 - activation_loss: 0.7773 - activation_1_loss: 0.7338\n","Epoch 00003: val_loss did not improve from 1.66411\n","550/550 [==============================] - 224s 407ms/step - loss: 1.5110 - activation_loss: 0.7773 - activation_1_loss: 0.7338 - val_loss: 1.6717 - val_activation_loss: 0.8472 - val_activation_1_loss: 0.8245\n","Loading model...\n","Predicting OOF...\n","138/138 [==============================] - 18s 133ms/step\n","Predicting Test...\n","172/172 [==============================] - 23s 134ms/step\n",">>>> FOLD 4 Jaccard = 0.7003649957693929\n","\n","#########################\n","### FOLD 5\n","#########################\n"],"name":"stdout"},{"output_type":"stream","text":["All model checkpoint layers were used when initializing TFRobertaModel.\n","\n","All the layers of TFRobertaModel were initialized from the model checkpoint at /content/drive/My Drive/Colab Notebooks/6000/pretrained-roberta-base.h5.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/3\n","550/550 [==============================] - ETA: 0s - loss: 2.1796 - activation_loss: 1.0833 - activation_1_loss: 1.0963\n","Epoch 00001: val_loss improved from inf to 1.70535, saving model to v0-roberta-4.h5\n","550/550 [==============================] - 228s 414ms/step - loss: 2.1796 - activation_loss: 1.0833 - activation_1_loss: 1.0963 - val_loss: 1.7053 - val_activation_loss: 0.8696 - val_activation_1_loss: 0.8357\n","Epoch 2/3\n","550/550 [==============================] - ETA: 0s - loss: 1.6344 - activation_loss: 0.8382 - activation_1_loss: 0.7961\n","Epoch 00002: val_loss improved from 1.70535 to 1.67590, saving model to v0-roberta-4.h5\n","550/550 [==============================] - 226s 410ms/step - loss: 1.6344 - activation_loss: 0.8382 - activation_1_loss: 0.7961 - val_loss: 1.6759 - val_activation_loss: 0.8493 - val_activation_1_loss: 0.8266\n","Epoch 3/3\n","550/550 [==============================] - ETA: 0s - loss: 1.4678 - activation_loss: 0.7585 - activation_1_loss: 0.7093\n","Epoch 00003: val_loss did not improve from 1.67590\n","550/550 [==============================] - 224s 407ms/step - loss: 1.4678 - activation_loss: 0.7585 - activation_1_loss: 0.7093 - val_loss: 1.7221 - val_activation_loss: 0.8602 - val_activation_1_loss: 0.8618\n","Loading model...\n","Predicting OOF...\n","138/138 [==============================] - 18s 133ms/step\n","Predicting Test...\n","172/172 [==============================] - 23s 135ms/step\n",">>>> FOLD 5 Jaccard = 0.6965065219303377\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aGRDVjt3LDFj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605521994653,"user_tz":-480,"elapsed":901,"user":{"displayName":"Lin CHENG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ktQ7itlqm_xlrJQa92rKtAgFOnq06TeqdgYR=s64","userId":"15737879624843884018"}},"outputId":"6e5947a2-3ded-49d8-c57b-a9e1535387ee"},"source":["print('>>>> OVERALL 5Fold CV Jaccard =',np.mean(jac))"],"execution_count":null,"outputs":[{"output_type":"stream","text":[">>>> OVERALL 5Fold CV Jaccard = 0.7051530928414108\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a3SuxQlHLDEC"},"source":["all = []\n","for k in range(input_ids_t.shape[0]):\n","    a = np.argmax(preds_start[k,])\n","    b = np.argmax(preds_end[k,])\n","    if a>b: \n","        st = test.loc[k,'text']\n","    else:\n","        text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n","        enc = tokenizer.encode(text1)\n","        st = tokenizer.decode(enc.ids[a-1:b])\n","    all.append(st)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0FyeQJWBLC_f"},"source":["test['selected_text'] = all"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XPf4U73dMf3C"},"source":["r = pd.DataFrame(test.copy()['selected_text'])\n","g = pd.DataFrame(sample.copy()['selected_text'])\n","g.rename(columns = {'selected_text':'groud_truth'},inplace = True)\n","result = r.join(g)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3x18dpYhMf5_"},"source":["score = []\n","\n","for ind,row in result.iterrows():\n","    sentence1 = row.groud_truth\n","    sentence2 = row.selected_text\n","\n","    jaccard_score = jaccard(sentence1,sentence2)\n","    score.append([sentence1,sentence2,jaccard_score])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kh2N75DmMf_B"},"source":["result = pd.DataFrame(score,columns=[\"groud_truth\",\"selected_text\",\"jaccard_score\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PnITya3EMgEL","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1605522502212,"user_tz":-480,"elapsed":571,"user":{"displayName":"Lin CHENG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ktQ7itlqm_xlrJQa92rKtAgFOnq06TeqdgYR=s64","userId":"15737879624843884018"}},"outputId":"3a794ad3-40b5-4d0e-ccfb-d98f596b5da4"},"source":["result"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>groud_truth</th>\n","      <th>selected_text</th>\n","      <th>jaccard_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>smH daTs whacK</td>\n","      <td>smh dats whack</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>oh dear, thats not good - I hope you get throu...</td>\n","      <td>oh dear, thats not good - i hope you get thro...</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>stuvk with the wee stpid thing fo</td>\n","      <td>its not letting me change my picture so your ...</td>\n","      <td>0.062500</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>uni email is helpful..</td>\n","      <td>appreciated,uni email is helpful..</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>, Just read an article that buying IP`s doesn`...</td>\n","      <td>, just read an article that buying ip`s doesn...</td>\n","      <td>0.944444</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5491</th>\n","      <td>MC, happy mother`s day to your mom ;).. love yah</td>\n","      <td>happy</td>\n","      <td>0.100000</td>\n","    </tr>\n","    <tr>\n","      <th>5492</th>\n","      <td>Glad you are happy!</td>\n","      <td>glad you are happy!</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>5493</th>\n","      <td>mcfly anit been on here in ages  z</td>\n","      <td>mcfly anit been on here in ages z</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>5494</th>\n","      <td>that`s not good to hear!  i hope everything is...</td>\n","      <td>that`s not good to hear! i hope everything is...</td>\n","      <td>0.409091</td>\n","    </tr>\n","    <tr>\n","      <th>5495</th>\n","      <td>inflating</td>\n","      <td>prices are inflating</td>\n","      <td>0.333333</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5496 rows Ã— 3 columns</p>\n","</div>"],"text/plain":["                                            groud_truth  ... jaccard_score\n","0                                        smH daTs whacK  ...      1.000000\n","1     oh dear, thats not good - I hope you get throu...  ...      1.000000\n","2                     stuvk with the wee stpid thing fo  ...      0.062500\n","3                                uni email is helpful..  ...      0.600000\n","4     , Just read an article that buying IP`s doesn`...  ...      0.944444\n","...                                                 ...  ...           ...\n","5491   MC, happy mother`s day to your mom ;).. love yah  ...      0.100000\n","5492                                Glad you are happy!  ...      1.000000\n","5493                 mcfly anit been on here in ages  z  ...      1.000000\n","5494  that`s not good to hear!  i hope everything is...  ...      0.409091\n","5495                                          inflating  ...      0.333333\n","\n","[5496 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":94}]},{"cell_type":"code","metadata":{"id":"YTrkcTHQMgJM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605522510811,"user_tz":-480,"elapsed":722,"user":{"displayName":"Lin CHENG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ktQ7itlqm_xlrJQa92rKtAgFOnq06TeqdgYR=s64","userId":"15737879624843884018"}},"outputId":"3a7456d7-3a3b-44da-b83a-c25cec974659"},"source":["result['jaccard_score'].mean()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7091341125706987"]},"metadata":{"tags":[]},"execution_count":95}]},{"cell_type":"code","metadata":{"id":"CAlsKbPsMgMs","colab":{"base_uri":"https://localhost:8080/","height":406},"executionInfo":{"status":"ok","timestamp":1605522546095,"user_tz":-480,"elapsed":790,"user":{"displayName":"Lin CHENG","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1ktQ7itlqm_xlrJQa92rKtAgFOnq06TeqdgYR=s64","userId":"15737879624843884018"}},"outputId":"ae62016a-92d9-437d-aa9a-1d4356186224"},"source":["import seaborn as sns\n","plt.figure(figsize=(12,6))\n","sns.distplot(result['jaccard_score'],kde=False)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fa60382e8d0>"]},"metadata":{"tags":[]},"execution_count":97},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}
